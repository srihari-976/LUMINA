# Llama Chatbot

A modern chatbot interface for the fine-tuned Llama 3 model, featuring a beautiful UI with dark mode support.

## Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py          # Flask backend serving the Llama model
â”‚   â””â”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Header.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.jsx
â”‚   â””â”€â”€ package.json
â””â”€â”€ Fine_Tuning_Script.py
```

## Features

- ğŸ¨ Modern, responsive UI with Material Design
- ğŸŒ™ Dark/Light mode support
- âš¡ Real-time chat interactions
- ğŸ“ Markdown support for bot responses
- ğŸ”„ Smooth animations and transitions
- ğŸ¯ Loading states and error handling

## Setup & Running

### Backend

1. Create a Python virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. Install dependencies:
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

3. Run the Flask server:
   ```bash
   python app.py
   ```

### Frontend

1. Install dependencies:
   ```bash
   cd frontend
   npm install
   ```

2. Start the development server:
   ```bash
   npm start
   ```

The application will be available at `http://localhost:3000`

## Environment Variables

Make sure to set up your Hugging Face API token in the backend:

```python
access_token = "your_huggingface_token"
```

## Contributing

Feel free to submit issues and enhancement requests! 